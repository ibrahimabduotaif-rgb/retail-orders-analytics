# =============================================================================
# 1. ุงุณุชูุฑุงุฏ ุงูููุชุจุงุช
# =============================================================================
# ููุงุญุธุฉ: ูู ุงููุณุฎุฉ ุงูุฃุตููุฉ ูู ููู ููุงู ุชูุธูู ููุงุณุชูุฑุงุฏ
# ุงูุชุญุณูู: ุชุฌููุน ุงูููุชุจุงุช ุญุณุจ ุงููุธููุฉ ูุน ุงูุชุนููู ุนูู ูู ูุฌููุนุฉ

import os
import logging
import zipfile
from datetime import datetime

import pandas as pd
import numpy as np
import sqlalchemy as sal
from sqlalchemy import text

# ุฅุนุฏุงุฏ ูุธุงู ุชุณุฌูู ุงูุนูููุงุช - ุบูุฑ ููุฌูุฏ ูู ุงููุณุฎุฉ ุงูุฃุตููุฉ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('etl_pipeline.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


# =============================================================================
# 2. ุฅุนุฏุงุฏุงุช ุงููุดุฑูุน (Configuration)
# =============================================================================
# โ ูุดููุฉ ูู ุงูุฃุตู: ุงูุฅุนุฏุงุฏุงุช ูุชูุงุซุฑุฉ ูู ุงูููุฏ
# โ ุงูุชุญุณูู: ุชุฌููุนูุง ูู ููุงู ูุงุญุฏ ูุณูููุฉ ุงูุชุนุฏูู

CONFIG = {
    # ูุณุงุฑุงุช ุงููููุงุช
    "dataset": "ankitbansal06/retail-orders",
    "zip_file": "orders.csv.zip",
    "csv_file": "orders.csv",

    # ุงูููู ุงูุชู ุชูุนุงูู ูู null
    # โ ููุทุฉ ููุฉ ููุฌูุฏุฉ ูู ุงูุฃุตู - ุชู ุชูุณูุนูุง ููุง
    "na_values": ['Not Available', 'unknown', 'N/A', 'NA', '', 'null', 'none'],

    # ุฅุนุฏุงุฏุงุช ูุงุนุฏุฉ ุงูุจูุงูุงุช
    # โ ูู ุงูุฃุตู: ุงุณู ุฌูุงุฒ ูุญุฏุฏ (ANKIT\\SQLEXPRESS) - ุบูุฑ ูุญููู
    # โ ุงูุชุญุณูู: ุงุณุชุฎุฏุงู ูุชุบูุฑุงุช ุจูุฆุฉ ุฃู SQLite ูุจุฏูู ูุญููู
    "db_connection": os.getenv(
        "DB_CONNECTION_STRING",
        "sqlite:///retail_orders.db"  # ุจุฏูู ูุญููู ูุนูู ุนูู ุฃู ุฌูุงุฒ
    ),
    "table_name": "df_orders",
}


# =============================================================================
# 3. ุงุณุชุฎุฑุงุฌ ุงูุจูุงูุงุช (Extract)
# =============================================================================
def extract_data() -> str:
    """
    ุชุญููู ูุงุณุชุฎุฑุงุฌ ุงูุจูุงูุงุช ูู Kaggle

    โ ูุดููุฉ ูู ุงูุฃุตู: ูุง ููุฌุฏ error handling
       ูู ูุดู ุงูุชุญููู ูููุงุฑ ุงูููุฏ ุจุงููุงูู
    โ ุงูุชุญุณูู: try-except ูุน ุฑุณุงุฆู ูุงุถุญุฉ
    """
    logger.info("โฌ๏ธ  ุจุฏุก ุชุญููู ุงูุจูุงูุงุช ูู Kaggle...")

    try:
        # ุชุญููู ูู Kaggle
        os.system(
            f'kaggle datasets download {CONFIG["dataset"]} '
            f'-f {CONFIG["csv_file"]}'
        )
        logger.info("โ ุชู ุงูุชุญููู ุจูุฌุงุญ")
    except Exception as e:
        logger.error(f"โ ูุดู ุงูุชุญููู: {e}")
        raise

    # ูู ุงูุถุบุท
    try:
        with zipfile.ZipFile(CONFIG["zip_file"], 'r') as zip_ref:
            zip_ref.extractall()
            # โ ุงูุชุญุณูู: ุงุณุชุฎุฏุงู context manager (with)
            # โ ูู ุงูุฃุตู: ูุชุญ ูุฅุบูุงู ูุฏูู - ุฎุทุฑ ูุณูุงู ุงูุฅุบูุงู
        logger.info("โ ุชู ูู ุงูุถุบุท ุจูุฌุงุญ")
    except FileNotFoundError:
        logger.error(f"โ ุงูููู ุบูุฑ ููุฌูุฏ: {CONFIG['zip_file']}")
        raise
    except zipfile.BadZipFile:
        logger.error("โ ุงูููู ุชุงูู ุฃู ููุณ ููู zip ุตุงูุญ")
        raise

    return CONFIG["csv_file"]


# =============================================================================
# 4. ุชุญููู ุงูุจูุงูุงุช (Transform)
# =============================================================================
def transform_data(filepath: str) -> pd.DataFrame:
    """
    ูุฑุงุกุฉ ูุชูุธูู ูุชุญููู ุงูุจูุงูุงุช

    ูุฐุง ุงููุณู ููู ุฃูุจุฑ ุงููุดุงูู ูู ุงููุณุฎุฉ ุงูุฃุตููุฉ:
    โ ุฃุบูุจ ุงูููุฏ ูุนููู (commented out) - ูุนูู ูุง ูุนูู ูุนููุงู!
    โ ูุง ููุฌุฏ ุชุญูู ูู ุงูุจูุงูุงุช ุจุนุฏ ูู ุฎุทูุฉ
    โ ูุง ููุฌุฏ ุชูุซูู ูููุทู ุงูุญุณุงุจุงุช
    """

    # --- 4.1 ูุฑุงุกุฉ ุงูุจูุงูุงุช ---
    logger.info("๐ ูุฑุงุกุฉ ุงูุจูุงูุงุช...")
    df = pd.read_csv(filepath, na_values=CONFIG["na_values"])

    # โ ุชุญูู ุฃููู - ุบูุฑ ููุฌูุฏ ูู ุงูุฃุตู
    logger.info(f"   ุนุฏุฏ ุงูุตููู: {len(df):,}")
    logger.info(f"   ุนุฏุฏ ุงูุฃุนูุฏุฉ: {df.shape[1]}")
    logger.info(f"   ุงูููู ุงููุงุฑุบุฉ:\n{df.isnull().sum()[df.isnull().sum() > 0]}")

    # --- 4.2 ุชูุธูู ุฃุณูุงุก ุงูุฃุนูุฏุฉ ---
    # โ ูู ุงูุฃุตู: ุงูููุฏ ูุนููู! ุงูุฃุนูุฏุฉ ุชุจูู ุจุฃุณูุงุฆูุง ุงููุฏููุฉ
    # โ ุงูุชุญุณูู: ุชูุนูู ุงูููุฏ ูุน ุญูุงูุฉ ุฅุถุงููุฉ
    original_columns = df.columns.tolist()
    df.columns = (
        df.columns
        .str.lower()
        .str.strip()              # ุฅุฒุงูุฉ ุงููุณุงูุงุช ุงูุฒุงุฆุฏุฉ
        .str.replace(' ', '_')
        .str.replace('[^a-z0-9_]', '', regex=True)  # ุฅุฒุงูุฉ ุงูุฑููุฒ ุงูุฎุงุตุฉ
    )
    logger.info(f"   ุชู ุชูุธูู ุงูุฃุนูุฏุฉ: {dict(zip(original_columns, df.columns))}")

    # --- 4.3 ุงุดุชูุงู ุงูุฃุนูุฏุฉ ุงูุฌุฏูุฏุฉ ---
    """
    โ ุฃุฎุทุงุก ูู ุงูุฃุตู:
       1. ุงูููุฏ ูุนููู ุจุงููุงูู!
       2. ุตูุบุฉ ุงูุฎุตู: df['list_price']*df['discount_percent']*.01
          - ุงูุถุฑุจ ูู 0.01 ูุนูู ุฃู discount_percent ูุฎุฒู ููุณุจุฉ ูุฆููุฉ (ูุซูุงู 20 = 20%)
          - ูุฐุง ุตุญูุญ ููู ูุญุชุงุฌ ุชูุซูู

    โ ุงูุชุญุณูู: ุชูุนูู ูุน ุชูุซูู ูุงุถุญ ูุชุญูู
    """

    # ุงูุชุญูู ูู ูุฌูุฏ ุงูุฃุนูุฏุฉ ุงููุทููุจุฉ ูุจู ุงูุญุณุงุจ
    required_cols = ['list_price', 'discount_percent', 'cost_price']
    missing_cols = [col for col in required_cols if col not in df.columns]
    if missing_cols:
        raise ValueError(f"โ ุฃุนูุฏุฉ ููููุฏุฉ: {missing_cols}")

    # ุญุณุงุจ ุงูุฎุตู: ูููุฉ ุงูุฎุตู = ุณุนุฑ ุงููุงุฆูุฉ ร (ูุณุจุฉ ุงูุฎุตู / 100)
    df['discount'] = df['list_price'] * df['discount_percent'] * 0.01

    # ุณุนุฑ ุงูุจูุน = ุณุนุฑ ุงููุงุฆูุฉ - ูููุฉ ุงูุฎุตู
    df['sale_price'] = df['list_price'] - df['discount']

    # ุงูุฑุจุญ = ุณุนุฑ ุงูุจูุน - ุณุนุฑ ุงูุชูููุฉ
    df['profit'] = df['sale_price'] - df['cost_price']

    # โ ุชุญูู ูู ููุทููุฉ ุงูุญุณุงุจุงุช - ุบูุฑ ููุฌูุฏ ูู ุงูุฃุตู
    negative_profit_count = (df['profit'] < 0).sum()
    negative_sale_count = (df['sale_price'] < 0).sum()

    if negative_sale_count > 0:
        logger.warning(f"โ๏ธ  ููุฌุฏ {negative_sale_count} ุตู ุจุณุนุฑ ุจูุน ุณุงูุจ!")
    if negative_profit_count > 0:
        logger.warning(
            f"โ๏ธ  ููุฌุฏ {negative_profit_count} ุตู ุจุฑุจุญ ุณุงูุจ "
            f"({negative_profit_count/len(df)*100:.1f}% ูู ุงูุจูุงูุงุช)"
        )

    # --- 4.4 ุชุญููู ุงูุชุงุฑูุฎ ---
    # โ ูู ุงูุฃุตู: ููุฌูุฏ ููู ุจุฏูู error handling
    try:
        df['order_date'] = pd.to_datetime(df['order_date'], format="%Y-%m-%d")
    except ValueError:
        logger.warning("โ๏ธ  ุชูุณูู ุงูุชุงุฑูุฎ ุบูุฑ ูุชุทุงุจูุ ูุญุงููุฉ ุงูุชุญููู ุงูุชููุงุฆู...")
        df['order_date'] = pd.to_datetime(df['order_date'], infer_datetime_format=True)

    # --- 4.5 ุญุฐู ุงูุฃุนูุฏุฉ ุงููุคูุชุฉ ---
    # โ ุงูุชุญุณูู: ุงูุชุญูู ูู ูุฌูุฏ ุงูุฃุนูุฏุฉ ูุจู ุงูุญุฐู
    cols_to_drop = ['list_price', 'cost_price', 'discount_percent']
    existing_to_drop = [col for col in cols_to_drop if col in df.columns]
    df.drop(columns=existing_to_drop, inplace=True)

    # --- 4.6 ููุฎุต ููุงุฆู ---
    logger.info("=" * 50)
    logger.info("๐ ููุฎุต ุงูุจูุงูุงุช ุจุนุฏ ุงูุชุญููู:")
    logger.info(f"   ุงูุตููู: {len(df):,}")
    logger.info(f"   ุงูุฃุนูุฏุฉ: {list(df.columns)}")
    logger.info(f"   ูุทุงู ุงูุชูุงุฑูุฎ: {df['order_date'].min()} โ {df['order_date'].max()}")
    logger.info(f"   ุฅุฌูุงูู ุงููุจูุนุงุช: ${df['sale_price'].sum():,.2f}")
    logger.info(f"   ุฅุฌูุงูู ุงูุฃุฑุจุงุญ: ${df['profit'].sum():,.2f}")
    logger.info(f"   ูุงูุด ุงูุฑุจุญ: {df['profit'].sum()/df['sale_price'].sum()*100:.1f}%")
    logger.info("=" * 50)

    return df


# =============================================================================
# 5. ุชุญููู ุงูุจูุงูุงุช (Load)
# =============================================================================
def load_data(df: pd.DataFrame) -> None:
    """
    ุชุญููู ุงูุจูุงูุงุช ุฅูู ูุงุนุฏุฉ ุงูุจูุงูุงุช

    โ ูุดุงูู ูู ุงูุฃุตู:
       1. ุงูุงุชุตุงู ูุฑุชุจุท ุจุฌูุงุฒ ูุญุฏุฏ (ANKIT\\SQLEXPRESS)
       2. ุงุณุชุฎุฏุงู 'append' ุจุฏูู ุชุญูู ูู ุงูุชูุฑุงุฑ
       3. ูุง ููุฌุฏ ุฅุบูุงู ููุงุชุตุงู
    โ ุงูุชุญุณููุงุช:
       1. ุงุชุตุงู ูุญููู ุนุจุฑ ูุชุบูุฑุงุช ุจูุฆุฉ
       2. ุงุณุชุฎุฏุงู 'replace' ุฃููุงู ุซู 'append' ุญุณุจ ุงูุญุงุฌุฉ
       3. ุฅุบูุงู ุชููุงุฆู ูุน context manager
    """
    logger.info(f"๐พ ุชุญููู ุงูุจูุงูุงุช ุฅูู: {CONFIG['db_connection'][:30]}...")

    try:
        engine = sal.create_engine(CONFIG["db_connection"])

        # ุงุฎุชุจุงุฑ ุงูุงุชุตุงู ุฃููุงู
        with engine.connect() as conn:
            conn.execute(text("SELECT 1"))
        logger.info("โ ุงูุงุชุตุงู ุจูุงุนุฏุฉ ุงูุจูุงูุงุช ูุงุฌุญ")

        # ุชุญููู ุงูุจูุงูุงุช
        # โ ุงุณุชุฎุฏุงู 'replace' ููุชุดุบูู ุงูุฃูู ูุชุฌูุจ ุชูุฑุงุฑ ุงูุจูุงูุงุช
        df.to_sql(
            CONFIG["table_name"],
            con=engine,
            index=False,
            if_exists='replace',  # โ ูู ุงูุฃุตู: 'append' ูุฏ ูููุฑุฑ ุงูุจูุงูุงุช
            chunksize=1000,       # โ ุชุญููู ุนูู ุฏูุนุงุช ูุชุญุณูู ุงูุฃุฏุงุก
            method='multi'        # โ ุฅุฏุฑุงุฌ ูุชุนุฏุฏ ุฃุณุฑุน
        )
        logger.info(f"โ ุชู ุชุญููู {len(df):,} ุตู ุจูุฌุงุญ")

    except sal.exc.OperationalError as e:
        logger.error(f"โ ูุดู ุงูุงุชุตุงู ุจูุงุนุฏุฉ ุงูุจูุงูุงุช: {e}")
        raise
    except Exception as e:
        logger.error(f"โ ุฎุทุฃ ุบูุฑ ูุชููุน: {e}")
        raise
    finally:
        engine.dispose()
        logger.info("๐ ุชู ุฅุบูุงู ุงูุงุชุตุงู")


# =============================================================================
# 6. ุงูุชุดุบูู ุงูุฑุฆูุณู
# =============================================================================
# โ ูู ุงูุฃุตู: ูุง ููุฌุฏ main function - ุงูููุฏ ูุนูู ุจุดูู ุฎุทู
# โ ุงูุชุญุณูู: ููููุฉ ูุงุถุญุฉ ูุน ููุงุณ ุงูููุช

def main():
    """ุชุดุบูู ETL Pipeline ุงููุงูู"""
    start_time = datetime.now()
    logger.info("๐ ุจุฏุก ุชุดุบูู ETL Pipeline")
    logger.info("=" * 60)

    try:
        # ุงููุฑุญูุฉ 1: ุงูุงุณุชุฎุฑุงุฌ
        csv_path = extract_data()

        # ุงููุฑุญูุฉ 2: ุงูุชุญููู
        df = transform_data(csv_path)

        # ุงููุฑุญูุฉ 3: ุงูุชุญููู
        load_data(df)

        elapsed = datetime.now() - start_time
        logger.info("=" * 60)
        logger.info(f"๐ ุงูุชูู ุจูุฌุงุญ ูู {elapsed.total_seconds():.1f} ุซุงููุฉ")

    except Exception as e:
        logger.error(f"๐ฅ ูุดู Pipeline: {e}")
        raise


if __name__ == "__main__":
    main()
